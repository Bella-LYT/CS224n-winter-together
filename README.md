## [CS224N-winter-together](https://github.com/xixiaoyao/CS224n.2020)

`CS224n-winter-together`（又叫`Stanford CS224n追剧计划`）是由微信公众号 [夕小瑶的卖萌屋](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485633&idx=1&sn=24f65254ae07f53ebb1d976b37d2573b&chksm=970c2017a07ba90182d85fc0a238d3234bd9fe3eb357371db756ba73e321f733d52658fe941b&token=1203749132&lang=zh_CN#rd) 发起的开源课程学习项目，**本项目旨在为大家提供一个课程笔记、感悟与延伸、课程作业与project的分享与内容沉淀平台**，每个人均可将自己的笔记、感悟、作业等提交到该repo下面对应课程的文件夹底下，来方便大家参考学习，具体细节见[提交流程](https://github.com/xixiaoyao/CS224n-winter-together/blob/master/README.md#%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%E6%84%9F%E6%82%9F%E5%92%8C%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B)。另外，鼓励大家以markdown格式进行提交以免repo大小增长过快。

本项目在2020年斯坦福大学开设的自然语言处理课程CS224n的基础上建立，注意，由于2020年的视频现在没有对外放出，因此视频资料是2019年的（不过连线斯坦福的小伙伴问了一下，区别不大，PPT也更新不大），其他资料均为今年的。

> Stanford CS224n官方课程主页：http://web.stanford.edu/class/cs224n

关于该计划的详细攻略见 [这里](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485633&idx=1&sn=24f65254ae07f53ebb1d976b37d2573b&chksm=970c2017a07ba90182d85fc0a238d3234bd9fe3eb357371db756ba73e321f733d52658fe941b&token=1203749132&lang=zh_CN#rd)



### 项目目录

```text
.
├── Lectures（课程资料）
│   ├── Class 1. Introduction and Word Vectors
|   |    ├── video（教学视频，配中英双语字幕） 
│   │    ├── slides (课件）
│   │    ├── additional readings（推荐阅读）
│   │    ├── FAQ（问题总结，整理自微信讨论群）
│   │    └── notes（官方笔记）
│   ├── Class ...
│   └── Class N 
│
├─── Assignments（课程作业）
│    ├─- Assignment 1
│    │   └── upload（大家在该目录上传自己完成的作业）
│    ├─- Assignment ...
│    └── Assignment N 
│
├─── Feature Notes（第三方笔记、感悟和延伸文章）
│    └── upload（大家在该目录上传自己完成的笔记、感悟和延伸文章，请务必保证原创）
│
└─── Projects（项目实战）
     └── upload（大家在该目录上传自己队伍完成的实战项目，目前暂未开放）
```

### 课程计划

微信公众号**夕小瑶的卖萌屋**将每周推送两集课程视频（中英双语字幕）和对应的官方ppt/笔记/推荐阅读材料等，并发布课后作业。

- [week1：Introduction and Word Vectors](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485594&idx=1&sn=ffb84da1be4042deac7067e20f620ada&chksm=970c204ca07ba95a2cc7a0ef6205356f859c88518b9a70a8b4c1901c4365254637f3eada56db&scene=21#wechat_redirect)
- [week2：Word Vectors 2 and Word Senses / Word Window Classification and Neural Networks](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485633&idx=1&sn=24f65254ae07f53ebb1d976b37d2573b&chksm=970c2017a07ba90182d85fc0a238d3234bd9fe3eb357371db756ba73e321f733d52658fe941b&scene=21#wechat_redirect)
- [week3：Matrix Calculus and Backpropagation / Linguistic Structure: Dependency Parsing](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485709&idx=1&sn=4d79ed9086289fef8a8e54dfb7f18104&chksm=970c21dba07ba8cd22b26767dcc85f6fc41c9e852ee9706d1ecf3787a3cdbdaa56735f207894&scene=21#wechat_redirect)
- [week4：The probability of a sentence? Recurrent Neural Networks and Language Models / Vanishing Gradients and Fancy RNNs](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485806&idx=2&sn=47eb994009c8b06113d2f88dedb570af&chksm=970c21b8a07ba8ae2f19d9599df37186168858c440beb7b844ae2dc80ff976d5645b1bf08c12&scene=21#wechat_redirect)
- [week5：Machine Translation, Seq2Seq and Attention / Practical Tips for Final Projects](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485842&idx=2&sn=5cb8c498db3d056f0dff43cd939b5bd1&chksm=970c2144a07ba85289cbaabca82e1fe0fe751ebde0682325d421cdaf7e25694df74e3db3ac4f&scene=21#wechat_redirect)
- [week6：Question Answering and the Default Final Project/ConvNets for NLP](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486036&idx=2&sn=ea7e8f545aa76fa92a21a93390ed9a9e&chksm=970c2282a07bab9409161f2fcd436130fa21bd621dcaecbf174d37556c40e6f5ba00fe1a8bc3&scene=21#wechat_redirect)
- [week7：Information from parts of words (Subword Models) and Transformer architectures / Contextual Word Representations: BERT](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486160&idx=2&sn=1d6ebd169bc9067391c92a0b3d31d626&chksm=970c2206a07bab101836fcf1d30a663690d6cd9f2b117fe8608ac50a9b9d9b2fd6f42e8d2835&scene=21#wechat_redirect)
- [week8：Modeling contexts of use: Contextual Representations and Pretraining / Natural Language Generation](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486184&idx=2&sn=db5c80724dd2a6fce8a4e8b69dcd5173&chksm=970c223ea07bab28b25cf7f67e9e9f65d0e80b71f1b4a0ded1897aaef9948bb981a6d3ff651e&scene=21#wechat_redirect)
- [week9：Reference in Language and Coreference Resolution / Fairness and Inclusion in AI](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486437&idx=2&sn=117d5bc76297c097f99440033303234b&chksm=970c2333a07baa2523a334550b824fcf7b653e6cd2d3de08a9b3e25c3803d5a8f0301ca90978&scene=21#wechat_redirect)
- [week10：Constituency Parsing and Tree Recursive Neural Networks / Recent Advances in Low Resource Machine Translation](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486486&idx=2&sn=05b012543a75629efe71c473088d3603&chksm=970c24c0a07badd65df1756c07945915704e31dcc595beacd965ac6ad8b31c739a970db99417&scene=21#wechat_redirect)
- [week11：Future of NLP + Deep Learning](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486666&idx=2&sn=b3e76532257ecf165d2d9567f1627350&chksm=970c241ca07bad0a37cb89e686ec72f5ee255952524a22623338c49b30d43a2a5b62136e003c&scene=38#wechat_redirect)


- [Week1：课程简介与词向量（附追剧计划详细攻略）](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485594&idx=1&sn=ffb84da1be4042deac7067e20f620ada&chksm=970c204ca07ba95a2cc7a0ef6205356f859c88518b9a70a8b4c1901c4365254637f3eada56db&scene=21#wechat_redirect)
- [Week2：词向量与词义/词窗分类与神经网络（附追剧计划详细攻略）](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485633&idx=1&sn=24f65254ae07f53ebb1d976b37d2573b&chksm=970c2017a07ba90182d85fc0a238d3234bd9fe3eb357371db756ba73e321f733d52658fe941b&scene=21#wechat_redirect)
- [Week3：矩阵计算与反向传播/语言学结构：依存分析（附上期复习回顾）](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485709&idx=1&sn=4d79ed9086289fef8a8e54dfb7f18104&chksm=970c21dba07ba8cd22b26767dcc85f6fc41c9e852ee9706d1ecf3787a3cdbdaa56735f207894&scene=21#wechat_redirect)
- [Week4：如何计算一个句子的概率？循环神经网络与语言模型/梯度消失问题与RNN变种（附上期精选作业/笔记/答疑/讨论）](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485806&idx=2&sn=47eb994009c8b06113d2f88dedb570af&chksm=970c21b8a07ba8ae2f19d9599df37186168858c440beb7b844ae2dc80ff976d5645b1bf08c12&scene=21#wechat_redirect)
- [Week5：Seq2Seq、注意力机制与机器翻译（附Final Project）](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247485842&idx=2&sn=5cb8c498db3d056f0dff43cd939b5bd1&chksm=970c2144a07ba85289cbaabca82e1fe0fe751ebde0682325d421cdaf7e25694df74e3db3ac4f&scene=21#wechat_redirect)
- [Week6：智能问答、Transformer、卷积神经网络](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486036&idx=2&sn=ea7e8f545aa76fa92a21a93390ed9a9e&chksm=970c2282a07bab9409161f2fcd436130fa21bd621dcaecbf174d37556c40e6f5ba00fe1a8bc3&scene=21#wechat_redirect)
- [Week7：subword models与上下文词表示](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486160&idx=2&sn=1d6ebd169bc9067391c92a0b3d31d626&chksm=970c2206a07bab101836fcf1d30a663690d6cd9f2b117fe8608ac50a9b9d9b2fd6f42e8d2835&scene=21#wechat_redirect)
- [Week8：上下文表示与文本生成](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486184&idx=2&sn=db5c80724dd2a6fce8a4e8b69dcd5173&chksm=970c223ea07bab28b25cf7f67e9e9f65d0e80b71f1b4a0ded1897aaef9948bb981a6d3ff651e&scene=21#wechat_redirect)
- [Week9：指代消歧与AI的公平和包容](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486437&idx=2&sn=117d5bc76297c097f99440033303234b&chksm=970c2333a07baa2523a334550b824fcf7b653e6cd2d3de08a9b3e25c3803d5a8f0301ca90978&scene=21#wechat_redirect)
- [Week10：成分句法分析与树递归神经网络](http://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486486&idx=2&sn=05b012543a75629efe71c473088d3603&chksm=970c24c0a07badd65df1756c07945915704e31dcc595beacd965ac6ad8b31c739a970db99417&scene=21#wechat_redirect)
- [Week11：NLP和深度学习的未来](https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247486666&idx=2&sn=b3e76532257ecf165d2d9567f1627350&chksm=970c241ca07bad0a37cb89e686ec72f5ee255952524a22623338c49b30d43a2a5b62136e003c&scene=38#wechat_redirect)


### 个人笔记、感悟和作业提交流程

请务必保证原创！若发现其他同学的笔记、作业等提交中有错误，鼓励提PR修复。另外，鼓励大家在上传的原创资料中留下联系方式，以便学习讨论和错误纠正。

**提交流程：**

*step 1.* fork项目并将个人仓库中的项目`git clone`到本地。

*step 2*. 在本地项目仓库中添加提交笔记、作业和课程项目到对应文件夹中，然后完成`git add`（文件添加）和`git commit`（本地提交）。

> 注意：cs224n的作业位于`Assignments`目录下，个人笔记和感悟位于`FeatureNotes`目录下，课程项目位于`Project`目录下。这三个目录均为开放性目录，每个人均可通过`pull request`来完成提交。提交细节请参考对应目录下的README文件。

*step 3.* 在本地完成的提交后，通过`git push`将本地提交推送至自己的github远程仓库后，发起`pull request`。

<center><img width="70%" src=".README/3.jpg"></img></center>

关于作业提交的详细git教程见 [这里](https://blog.csdn.net/zyy617532750/article/details/104262005)


### 课前准备FAQ

1. 我想看往年的课件和讲义，去哪儿下载？

   答：http://web.stanford.edu/class/cs224n/

2. 现在的课程视频哪里有？

   答：目前公开的最新视频是2019年的，在[youtube](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)和[B站](https://www.bilibili.com/video/av55089927?from=search&seid=5422333259356167279)上都有。**推荐关注微信公众号『夕小瑶的卖萌屋』，我们会每周更新两节课，推送课件和字幕校对后的视频。**

3. 我在学习过程中有一些疑问，怎么办？

   答：建议首先在issues里面搜索相关问题，看看有没有帮助。仍然不能解决的，可以通过微信交流群（推荐）或github issue提出问题，我们会及时解答和归档。每节课归档后的问题集在对应的『问题』目录下面，供大家复习。

4. 有没有免费的GPU可以用来完成作业？

   答：我们推荐使用AiStudio、Colab和Kaggle Kernel。具体教程可以百度or谷歌一下。

---

   极力建议大家加入`夕小瑶@Stanford CS224n追剧群`与上千小伙伴一起打卡交流学习，通过微信交流群（推荐）或github issue提出的问题，我们将定期精选并在每期的订阅号文章推送和本github项目中沉淀。

<center><img width="70%" src=".README/xxy_2.jpeg"></img></center>
